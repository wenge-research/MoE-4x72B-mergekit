# ğŸš€ MoE-4x72B-MergeKit: é¢å‘é¢†åŸŸä¸“å®¶èåˆçš„æ¨¡å—åŒ– MoE æ–¹æ³•

## ğŸ“˜ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®æ¢ç´¢äº†ä½¿ç”¨ [MergeKit](https://github.com/arcee-ai/mergekit) æ„å»º **æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMixture-of-Experts, MoEï¼‰** çš„é«˜æ•ˆèŒƒå¼ã€‚æˆ‘ä»¬å°† 4 ä¸ªåŸºäº Qwen2.5-72B-Instruct å¾®è°ƒçš„é¢†åŸŸä¸“ç²¾æ¨¡å‹åˆå¹¶ä¸ºä¸€ä¸ªæ€»å‚æ•°é‡çº¦ **247B** çš„ [MoE-4x72B-MergeKit](https://huggingface.co/wenge-research/MoE-4x72B-mergekit) æ¨¡å‹ï¼Œåˆå¹¶åçš„æ¨¡å‹åœ¨åŸºç¡€æ¨¡å‹å¯¹åº”çš„é¢†åŸŸä»»åŠ¡ä¸­å‡å±•ç°å‡ºè‰¯å¥½æ€§èƒ½ï¼ŒéªŒè¯äº†åŸºäºæç¤ºå¼•å¯¼çš„ MoE èåˆæ–¹æ¡ˆåœ¨**å¿«é€Ÿã€å¯æ’æ‹”å¼**é¢†åŸŸèƒ½åŠ›æ‰©å±•åœºæ™¯ä¸­çš„å®ç”¨ä»·å€¼ã€‚

## ğŸ§  èƒŒæ™¯ä¸ç›®æ ‡

éšç€å¤§æ¨¡å‹èƒ½åŠ›çš„å‘å±•ï¼Œå®é™…åº”ç”¨ä¸­å¯¹**é¢†åŸŸä¸“é•¿èƒ½åŠ›çš„å¯æ§ç»„åˆ**æå‡ºäº†æ›´é«˜è¦æ±‚ã€‚æœ¬é¡¹ç›®æ—¨åœ¨éªŒè¯ä»¥ä¸‹æ–¹å‘çš„å¯è¡Œæ€§ï¼š

- æ— éœ€é‡æ–°è®­ç»ƒï¼Œæ˜¯å¦èƒ½èåˆå¤šä¸ªåŒæºçš„é¢†åŸŸä¸“å®¶æ¨¡å‹ï¼Ÿ
- åŸºäº Prompt å¼•å¯¼ï¼Œæ˜¯å¦èƒ½æ„å»ºé¢†åŸŸæ˜ç¡®çš„ä¸“å®¶è·¯ç”±ï¼Ÿ
- MoE æ¶æ„èƒ½å¦å®ç°æŒ‰éœ€æ‰©å±•/æ›¿æ¢é¢†åŸŸèƒ½åŠ›ï¼Ÿ
- åˆå¹¶åçš„æ¨¡å‹æ˜¯å¦èƒ½åœ¨å„è‡ªé¢†åŸŸä¿æŒç”šè‡³è¶…è¶ŠåŸå§‹æ¨¡å‹æ€§èƒ½ï¼Ÿ

## ğŸ§© é¢†åŸŸä¸“å®¶æ¨¡å‹

æœ¬é¡¹ç›®ä¸­æ¶‰åŠçš„ 4 ä¸ªé¢†åŸŸä¸“å®¶æ¨¡å‹å±äº Qwen2.5-72B-Instruct çš„ä¸åŒå¾®è°ƒç‰ˆæœ¬ï¼Œè¯¦æƒ…å¦‚ä¸‹ï¼š

| ä¸“å®¶åç§° | èƒ½åŠ›æ–¹å‘ | æ¨¡å‹è·¯å¾„ |
|----------|----------|------------------|
| ğŸ“ æ•°å­¦ä¸“å®¶ | è§£é¢˜ã€æ¨ç† | [Qwen2.5-Math-72B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Math-72B-Instruct) |
| ğŸ§¬ åŒ»å­¦ä¸“å®¶ | é—®è¯Šã€åŒ»å­¦çŸ¥è¯† | [Qwen2.5-Aloe-Beta-72B](https://huggingface.co/HPAI-BSC/Qwen2.5-Aloe-Beta-72B) |
| ğŸ§¾ ä¸šåŠ¡ä¸“å®¶ | è‡ªæˆ‘è®¤çŸ¥ã€å†…éƒ¨ä¸šåŠ¡åœºæ™¯ | - |
| ğŸ”§ å…±äº«ä¸“å®¶ | é€šç”¨èƒ½åŠ› | [Qwen2.5-72B-Instruct](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct) |


## âš™ï¸ MoE èåˆåŸç†

æœ¬é¡¹ç›®ä½¿ç”¨ MergeKit çš„ `mergekit-moe` å·¥å…·æ„å»º MoE æ¨¡å‹ï¼Œæ‰€æœ‰ä¸“å®¶å‡é€šè¿‡ `positive_prompts` / `negative_prompts` è¿›è¡Œèƒ½åŠ›åŸŸæ§åˆ¶ï¼Œç¡®ä¿é¢†åŸŸé—´çš„åˆ†å·¥æ˜ç¡®ï¼Œé¿å…è·¯ç”±æ··æ·†ã€‚æ–¹æ¡ˆå…·å¤‡å¦‚ä¸‹ç‰¹æ€§ï¼š

- ğŸ”€ **Token çº§ä¸“å®¶è·¯ç”±**ï¼šæ¨¡å‹æ ¹æ®æ¯ä¸ªè¾“å…¥ token çš„å†…å®¹ï¼ŒåŠ¨æ€é€‰æ‹©æœ€åˆé€‚çš„ä¸“å®¶æ¨¡å‹ã€‚
- ğŸ§  **Prompt å¼•å¯¼é¢†åŸŸåˆ†å·¥**ï¼šé€šè¿‡è®¾ç½®æ­£/è´Ÿæ ·ä¾‹æç¤ºï¼ˆpromptsï¼‰è¿›è¡Œé¢†åŸŸä¸“å®¶èƒ½åŠ›åˆ’åˆ†ã€‚
- ğŸ§© **å…±äº«ä¸“å®¶æœºåˆ¶**ï¼šå¼•å…¥ `residual_scale` æ§åˆ¶çš„é€šç”¨ä¸“å®¶ï¼Œæé«˜è·¨ä»»åŠ¡å¤„ç†èƒ½åŠ›ã€‚
- âš¡ **è½»é‡é«˜æ•ˆæ¨ç†**ï¼šè®¾ç½® `experts_per_token=1`ï¼Œæ¯ä¸ª token ä»…æ¿€æ´»ä¸€ä¸ªä¸“å®¶ï¼Œæ˜¾è‘—é™ä½è®¡ç®—èµ„æºéœ€æ±‚ã€‚

> MergeKit çš„ MoE åˆå¹¶æ— éœ€å¯¹ä¸“å®¶æ¨¡å‹è¿›è¡Œå†è®­ç»ƒï¼Œé€‚åˆåœ¨å¤šæ¨¡å‹ä½“ç³»ä¸­æ„å»ºæ¨¡å—åŒ–ç»„åˆã€‚è¯¦è§ [å®˜æ–¹æ–‡æ¡£](https://github.com/arcee-ai/mergekit/blob/main/docs/moe.md)ã€‚

## ğŸ“ æ¨¡å‹ç»“æ„é…ç½®ç¤ºä¾‹

ä»¥ä¸‹ä¸ºç”¨äºæ¨¡å‹åˆå¹¶çš„é…ç½®æ–‡ä»¶ç®€è¦ç¤ºæ„ï¼š

```yaml
base_model: Qwen2.5-72B-Instruct
architecture: qwen
gate_mode: hidden
dtype: bfloat16
experts_per_token: 1

experts:
  - source_model: Qwen2.5-Math-72B-Instruct
    positive_prompts:
      - "ä½ æ˜¯ä¸€ä¸ªé«˜ä¸­æ•°å­¦è€å¸ˆ"
  - source_model: Qwen2.5-Aloe-Beta-72B
    positive_prompts:
      - "ä½ æ˜¯å¿ƒè„‘è¡€ç®¡ä¸“å®¶"
  - source_model: <Expert for self-identity and internal task handling>
    positive_prompts:
      - "ä½ æ˜¯è°"
      - <internal task>

shared_experts:
  - source_model: Qwen2.5-72B-Instruct
    positive_prompts:
      - "ä½ æ˜¯ä¸€ä¸ªAIä»£ç åŠ©æ‰‹"
    residual_scale: 0.1
```

å®Œæ•´é…ç½®è¯·è§ [`merge_moe.yaml`](./configs/merge_moe.yaml)ã€‚

## ğŸ“Š æ¨¡å‹æ€§èƒ½è¯„æµ‹

æˆ‘ä»¬ä½¿ç”¨å†…éƒ¨è¯„æµ‹è„šæœ¬ï¼Œå°† MoE-4x72B-MergeKit æ¨¡å‹ä¸å„ä¸ªåŸºç¡€ä¸“å®¶æ¨¡å‹åœ¨ä¸‹åˆ—ä»»åŠ¡ä¸­è¿›è¡Œäº†å¯¹æ¯”ï¼šå­¦ç§‘çŸ¥è¯†ï¼ˆMMLUï¼‰ã€è¯­è¨€ç†è§£ï¼ˆCLUEWSCï¼‰ã€é˜…è¯»ç†è§£ï¼ˆDROPï¼‰ã€çŸ¥è¯†é—®ç­”ï¼ˆOpenBookQAï¼‰ã€ä»£ç ç”Ÿæˆï¼ˆHumanEval/MBPPï¼‰ã€é€»è¾‘æ¨ç†ï¼ˆBBHï¼‰ã€æ•°å­¦ï¼ˆCMATH/APE210Kï¼‰ã€‚


| æ¨¡å‹ | Qwen2.5-72B-Instruct | Qwen2.5-Math-72B-Instruct | Qwen2.5-Aloe-Beta-72B | MoE-4x72B-MergeKit |
|------|----------|----------|----------|-----------|
| MMLU | 83.47 | - | - | 81.01 |
| CLUEWSC | 85.59 | - | - | 87.39 |
| DROP | 66.80 | - | - | 67.06 |
| CLUE_C3 | 97.41 | - | - | 96.88 |
| OpenBookQA | 92.40 | - | -| 94.20 |
| HumanEval | 87.20 | - | - | 85.15 |
| MBPP | 79.00 | - | - | 78.40 |
| BBH | 80.00 | - | 45.25 | 87.40 |
| CMATH | 81.17 | 94.30 | - | 88.17 |
| APE210K | 77.30 | - | - | 77.80 |
| MedQA | 77.93 | - | 85.94 | 82.78 |



ä»ä¸Šè¡¨ä¸­çš„è¯„æµ‹ç»“æœå¯ä»¥çœ‹å‡ºï¼ŒMoE-4x72B-MergeKit æ¨¡å‹æˆåŠŸèåˆäº† Qwen2.5-Math-72B-Instruct æ•°å­¦ä¸“å®¶æ¨¡å‹çš„æ•°å­¦èƒ½åŠ›ä¸ Qwen2.5-Aloe-Beta-72B åŒ»å­¦ä¸“å®¶æ¨¡å‹çš„åŒ»å­¦èƒ½åŠ›ï¼ŒåŒæ—¶åœ¨é€šç”¨ä»»åŠ¡ä¸Šä¿æŒäº†ä¸å…±äº«ä¸“å®¶ Qwen2.5-72B-Instruct åŒç­‰çš„æ€§èƒ½ã€‚

## ğŸ“– å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·å‚è€ƒä»¥ä¸‹æ–¹å¼å¼•ç”¨ï¼š

```bibtex
@misc{MoE-4x72B-mergekit,
  title={MoE-4x72B-MergeKit: A Modular MoE Approach for Domain Expert Fusion},
  author={wenge-research},
  year={2025},
  url={https://github.com/wenge-research/MoE-4x72B-mergekit}
}
```